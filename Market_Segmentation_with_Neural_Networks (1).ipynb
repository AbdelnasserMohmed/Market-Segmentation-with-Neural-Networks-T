{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FuqadHOqyyn",
        "outputId": "99a476ca-eaf5-4a20-e132-44c82837a50b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-51fd8269a241>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'])\n",
            "<ipython-input-2-51fd8269a241>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['TotalPrice'] = data['Quantity'] * data['UnitPrice']\n",
            "<ipython-input-2-51fd8269a241>:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Year'] = data['InvoiceDate'].dt.year\n",
            "<ipython-input-2-51fd8269a241>:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Month'] = data['InvoiceDate'].dt.month\n",
            "<ipython-input-2-51fd8269a241>:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['DayOfWeek'] = data['InvoiceDate'].dt.dayofweek\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1836/1836 [==============================] - 5s 2ms/step - loss: 0.0103 - mae: 0.0230 - val_loss: 2.5351e-04 - val_mae: 0.0048\n",
            "Epoch 2/5\n",
            "1836/1836 [==============================] - 4s 2ms/step - loss: 0.0036 - mae: 0.0120 - val_loss: 0.0023 - val_mae: 0.0098\n",
            "Epoch 3/5\n",
            "1836/1836 [==============================] - 5s 3ms/step - loss: 0.0011 - mae: 0.0072 - val_loss: 0.0891 - val_mae: 0.0139\n",
            "Epoch 4/5\n",
            "1836/1836 [==============================] - 3s 2ms/step - loss: 8.5163e-04 - mae: 0.0091 - val_loss: 0.0028 - val_mae: 0.0062\n",
            "Epoch 5/5\n",
            "1836/1836 [==============================] - 4s 2ms/step - loss: 0.0010 - mae: 0.0072 - val_loss: 7.4061e-04 - val_mae: 0.0036\n",
            "574/574 [==============================] - 1s 1ms/step - loss: 0.0200 - mae: 0.0045\n",
            "Loss: 0.019992444664239883, Mean Absolute Error: 0.004477945622056723\n",
            "2869/2869 [==============================] - 5s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('/content/data.csv', encoding='ISO-8859-1')\n",
        "\n",
        "# Initial cleaning and handling missing values\n",
        "data['Description'].fillna('No description', inplace=True)\n",
        "data.dropna(subset=['CustomerID'], inplace=True)\n",
        "data = data[(data['Quantity'] > 0) & (data['UnitPrice'] > 0)]\n",
        "data['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'])\n",
        "\n",
        "# Feature Engineering\n",
        "data['TotalPrice'] = data['Quantity'] * data['UnitPrice']\n",
        "data['Year'] = data['InvoiceDate'].dt.year\n",
        "data['Month'] = data['InvoiceDate'].dt.month\n",
        "data['DayOfWeek'] = data['InvoiceDate'].dt.dayofweek\n",
        "\n",
        "purchase_count = data.groupby('CustomerID')['InvoiceNo'].count().reset_index()\n",
        "purchase_count.columns = ['CustomerID', 'PurchaseCount']\n",
        "data = data.merge(purchase_count, on='CustomerID', how='left')\n",
        "\n",
        "average_purchase_value = data.groupby('CustomerID')['TotalPrice'].mean().reset_index()\n",
        "average_purchase_value.columns = ['CustomerID', 'AvgPurchaseValue']\n",
        "data = data.merge(average_purchase_value, on='CustomerID', how='left')\n",
        "\n",
        "# Encoding and Normalizing\n",
        "data = pd.get_dummies(data, columns=['Country'])\n",
        "scaler = StandardScaler()\n",
        "features_to_normalize = ['Quantity', 'UnitPrice', 'TotalPrice', 'PurchaseCount', 'AvgPurchaseValue']\n",
        "data[features_to_normalize] = scaler.fit_transform(data[features_to_normalize])\n",
        "\n",
        "# Define features and target\n",
        "features = data.drop(columns=['InvoiceNo', 'StockCode', 'Description', 'InvoiceDate', 'CustomerID', 'Year', 'Month', 'DayOfWeek'])\n",
        "target = data['PurchaseCount']  # Example target column\n",
        "\n",
        "# Ensure no NaN values in features and target\n",
        "features.fillna(0, inplace=True)\n",
        "target.fillna(0, inplace=True)\n",
        "\n",
        "# Convert all features to float32\n",
        "features = features.astype('float32')\n",
        "\n",
        "# Train-test split\n",
        "X = features.values\n",
        "y = target.values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ensure all data types are float\n",
        "X_train = X_train.astype(float)\n",
        "y_train = y_train.astype(float)\n",
        "X_test = X_test.astype(float)\n",
        "y_test = y_test.astype(float)\n",
        "\n",
        "# Neural Network Model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=features.shape[1], activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, mae = model.evaluate(X_test, y_test)\n",
        "print(f'Loss: {loss}, Mean Absolute Error: {mae}')\n",
        "\n",
        "# Predictions for market segmentation\n",
        "predictions = model.predict(X.astype('float32'))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iFIpLF_grDXB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}